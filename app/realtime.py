"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°å…¥åŠ›ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§èªè­˜
"""

import numpy as np
import threading
import time
import queue
import collections
import logging
from typing import Optional, Callable, List
import sys


class RealtimeTranscriber:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config, model, show_level: bool = False):
        """
        Args:
            config: WhisperConfigè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            model: Whisperãƒ¢ãƒ‡ãƒ«
            show_level: éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºã®æœ‰åŠ¹/ç„¡åŠ¹
        """
        self.config = config
        self.model = model
        self.show_level = show_level
        self.logger = logging.getLogger(__name__)
        
        # éŸ³å£°å…¥åŠ›è¨­å®š
        self.chunk_size = self.config.chunk_size
        self.channels = 1
        self.rate = self.config.sample_rate
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_recording = False
        self.audio_queue = queue.Queue()
        
        # Silero VADè¨­å®š
        try:
            import torch
            # torch.hubã‹ã‚‰ç›´æ¥ãƒ­ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªãƒ‘ã‚¹å¯¾å¿œï¼‰
            self.vad_model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                trust_repo=True
            )
            self.vad_available = True
            self.logger.info(f"Silero VADåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            self.logger.warning(f"Silero VADã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚VADãªã—ã§å‹•ä½œã—ã¾ã™ã€‚")
            self.vad_available = False
        
        self.frame_duration = self.config.frame_duration_ms  # ms
        self.frame_size = int(self.rate * self.frame_duration / 1000)
        
        # å…ˆé ­/æœ«å°¾ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ç”¨ãƒãƒƒãƒ•ã‚¡
        self.pre_speech_samples = int(self.rate * self.config.pre_speech_padding_ms / 1000)
        self.post_speech_samples = int(self.rate * self.config.post_speech_padding_ms / 1000)
        self.pre_speech_buffer = collections.deque(maxlen=max(1, self.pre_speech_samples))
        
        # éŸ³å£°ãƒãƒƒãƒ•ã‚¡
        self.audio_buffer = collections.deque(maxlen=int(self.rate * self.config.max_duration))
        
        # éŸ³å£°æ¤œå‡ºã®çŠ¶æ…‹
        self.in_speech = False
        self.silence_counter = 0
        self.silence_threshold = int(self.config.pause_threshold * self.rate / self.frame_size)
        
        # sounddeviceã®é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        self.sd = None
        
    def _get_sounddevice(self):
        """sounddeviceã®é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        if self.sd is None:
            import sounddevice as sd
            self.sd = sd
        return self.sd
    
    def list_microphones(self) -> List[dict]:
        """åˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒªã‚¹ãƒˆ"""
        sd = self._get_sounddevice()
        devices = sd.query_devices()
        
        microphones = []
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                microphones.append({
                    'id': i,
                    'name': device['name'],
                    'channels': device['max_input_channels'],
                    'default_samplerate': device['default_samplerate']
                })
        
        return microphones
    
    def select_microphone(self) -> Optional[int]:
        """ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã‚’é¸æŠ"""
        microphones = self.list_microphones()
        
        if not microphones:
            self.logger.error("åˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        print("\nåˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹:")
        for mic in microphones:
            print(f"  [{mic['id']}] {mic['name']} ({mic['channels']}ch, {mic['default_samplerate']:.0f}Hz)")
        
        while True:
            try:
                device_id = input(f"\nãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0): ").strip()
                if not device_id:
                    return 0
                device_id = int(device_id)
                if any(mic['id'] == device_id for mic in microphones):
                    return device_id
                print("ç„¡åŠ¹ãªãƒ‡ãƒã‚¤ã‚¹IDã§ã™ã€‚ã‚‚ã†ä¸€åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            except ValueError:
                print("æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            except KeyboardInterrupt:
                print("\nã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                return None
    
    def _audio_callback(self, indata, frames, time_info, status):
        """sounddeviceã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            self.logger.warning(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
        
        # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
        audio_data = indata[:, 0] if indata.ndim > 1 else indata
        
        # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        self.audio_queue.put(audio_data.copy())
    
    def _process_audio(self):
        """éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        self.logger.info("éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        while self.is_recording:
            try:
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                audio_chunk = self.audio_queue.get(timeout=0.1)
                
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤º
                if self.show_level:
                    level = np.abs(audio_chunk).mean()
                    bar_length = int(level * 50)
                    bar = 'â–ˆ' * bar_length
                    print(f'\réŸ³å£°ãƒ¬ãƒ™ãƒ«: [{bar:<50}] {level:.3f}', end='', flush=True)
                
                # éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                self.audio_buffer.extend(audio_chunk)
                self.pre_speech_buffer.extend(audio_chunk)
                
                # VADã§éŸ³å£°æ¤œå‡º
                # Silero VADã¯æœ€ä½512ã‚µãƒ³ãƒ—ãƒ«ï¼ˆç´„32msï¼‰å¿…è¦
                min_vad_samples = 512
                if self.vad_available and len(self.audio_buffer) >= min_vad_samples:
                    # ç¾åœ¨ã®ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰éŸ³å£°ã®æœ‰ç„¡ã‚’åˆ¤å®š
                    # æœ€ä½ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç¢ºä¿
                    vad_window_size = max(self.frame_size, min_vad_samples)
                    buffer_array = np.array(list(self.audio_buffer)[-vad_window_size:], dtype=np.float32)
                    
                    # VADã§éŸ³å£°æ¤œå‡º
                    import torch
                    audio_tensor = torch.from_numpy(buffer_array).unsqueeze(0)
                    speech_prob = self.vad_model(audio_tensor, self.rate).item()
                    
                    is_speech = speech_prob > self.config.vad_threshold
                    
                    if is_speech:
                        if not self.in_speech:
                            # éŸ³å£°é–‹å§‹
                            self.in_speech = True
                            self.silence_counter = 0
                            self.logger.debug("éŸ³å£°æ¤œå‡ºé–‹å§‹")
                    else:
                        if self.in_speech:
                            self.silence_counter += 1
                            
                            # ç„¡éŸ³ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰èªè­˜å®Ÿè¡Œ
                            if self.silence_counter >= self.silence_threshold:
                                self._recognize_audio()
                                self.in_speech = False
                                self.silence_counter = 0
                                self.audio_buffer.clear()
                                
            except queue.Empty:
                continue
            except Exception as e:
                self.logger.error(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        
        self.logger.info("éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    
    def _recognize_audio(self):
        """éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ"""
        if len(self.audio_buffer) < self.rate * self.config.phrase_threshold:
            self.logger.debug("éŸ³å£°ãŒçŸ­ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return
        
        try:
            # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            audio_data = np.array(list(self.audio_buffer), dtype=np.float32)
            
            # éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
            audio_level = np.abs(audio_data).mean()
            if audio_level < self.config.min_audio_level:
                self.logger.debug(f"éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒä½ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {audio_level:.4f}")
                return
            
            if self.show_level:
                print()  # æ”¹è¡Œ
            
            self.logger.info(f"éŸ³å£°èªè­˜ä¸­... ({len(audio_data)/self.rate:.1f}ç§’)")
            start_time = time.time()
            
            # éŸ³å£°èªè­˜å®Ÿè¡Œ
            result = self.model.transcribe_audio_segment(audio_data)
            
            elapsed = time.time() - start_time
            
            if result and result.strip():
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if len(result) < self.config.min_length:
                    self.logger.debug(f"æœ€å°æ–‡å­—æ•°æœªæº€ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {result}")
                    return
                
                if self.config.exclude_whitespace_only and not result.strip():
                    return
                
                # çµæœè¡¨ç¤ºï¼ˆè©±è€…åä»˜ãï¼‰
                speaker_info = f"[{self.config.microphone_speaker}]" if self.config.microphone_speaker else ""
                print(f"\nğŸ¤ èªè­˜çµæœ {speaker_info} ({elapsed:.2f}ç§’): {result}")
                
                # WebSocketé€ä¿¡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if self.config.microphone_send_to_websocket:
                    self._send_to_websocket(result)
                    
            else:
                self.logger.debug("èªè­˜çµæœãªã—")
                
        except Exception as e:
            self.logger.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def _send_to_websocket(self, text: str):
        """WebSocketã§çµæœã‚’é€ä¿¡"""
        try:
            import asyncio
            import websockets
            import json
            
            async def send():
                uri = f"ws://{self.config.websocket_host}:{self.config.websocket_port}/"
                async with websockets.connect(uri) as websocket:
                    notification = {
                        "jsonrpc": "2.0",
                        "method": "notifications/subtitle",
                        "params": {
                            "text": text,
                            "speaker": self.config.microphone_speaker,
                            "type": "subtitle",
                            "language": "ja"
                        }
                    }
                    await websocket.send(json.dumps(notification, ensure_ascii=False))
                    self.logger.debug(f"WebSocketã«é€ä¿¡: speaker={self.config.microphone_speaker}, text={text}")
            
            # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã§å®Ÿè¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(send())
            loop.close()
            
        except Exception as e:
            self.logger.error(f"WebSocketé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
    
    def start(self, device_id: Optional[int] = None):
        """éŸ³å£°èªè­˜ã‚’é–‹å§‹"""
        sd = self._get_sounddevice()
        
        # ãƒ‡ãƒã‚¤ã‚¹ID ã®å‡¦ç†
        if device_id is None:
            device_str = self.config.microphone_device_id
            if device_str == 'auto':
                device_id = self.select_microphone()
                if device_id is None:
                    return
            else:
                try:
                    device_id = int(device_str)
                except ValueError:
                    device_id = 0
        
        self.logger.info(f"ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹: {device_id}")
        
        # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±è¡¨ç¤º
        device_info = sd.query_devices(device_id)
        self.logger.info(f"ãƒ‡ãƒã‚¤ã‚¹å: {device_info['name']}")
        self.logger.info(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {self.rate}Hz")
        
        # éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self.is_recording = True
        process_thread = threading.Thread(target=self._process_audio, daemon=True)
        process_thread.start()
        
        # éŸ³å£°å…¥åŠ›é–‹å§‹
        try:
            print("\n" + "="*60)
            print("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™")
            print("="*60)
            print("Ctrl+C ã§çµ‚äº†")
            print()
            
            with sd.InputStream(
                device=device_id,
                channels=self.channels,
                samplerate=self.rate,
                blocksize=self.chunk_size,
                callback=self._audio_callback
            ):
                while self.is_recording:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            print("\n\néŸ³å£°èªè­˜ã‚’çµ‚äº†ã—ã¾ã™...")
        except Exception as e:
            self.logger.error(f"éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        finally:
            self.stop()
    
    def stop(self):
        """éŸ³å£°èªè­˜ã‚’åœæ­¢"""
        self.logger.info("éŸ³å£°èªè­˜ã‚’åœæ­¢ä¸­...")
        self.is_recording = False
        time.sleep(0.5)  # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†ã‚’å¾…ã¤
        self.logger.info("éŸ³å£°èªè­˜ã‚’åœæ­¢ã—ã¾ã—ãŸ")

