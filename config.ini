# MenZ-Whisper 設定ファイル
# OpenAI Whisperベースの音声認識システムの動作をカスタマイズできます
# 設定を変更した後は、プログラムを再起動してください

[mode]
# 動作モード選択
# network: ネットワーク経由のSTT依頼（zagaroid連携・デフォルト）
# microphone: マイクからの直接入力（リアルタイム音声認識）
mode = network

[microphone]
# マイク入力設定（mode=microphoneの時のみ有効）

# マイクデバイスID
# 0: デフォルトマイク
# 1, 2, 3...: 特定のマイクデバイス
# auto: 自動選択（起動時に選択画面表示）
device_id = 1

# 話者名（マイク入力時の話者識別子）
# 例: user, host, speaker_1, my_name など
speaker = zagan

# 音声レベル表示
# true: リアルタイムで音声レベルを表示
# false: 非表示
show_level = true

# WebSocket送信（マイクモード時の結果送信）
# true: 認識結果をzagaroidに送信
# false: コンソールのみに表示
send_to_websocket = false

[model]
# 使用する音声認識モデル
# tiny, base, small, medium, large, large-v2, large-v3
# tiny: 最速（精度低）、large-v3: 最高精度（処理重）
#model_size = base
#model_size = small
#model_size = large-v3-turbo
model_size = RoachLin/kotoba-whisper-v2.2-faster

# モデルファイルのキャッシュディレクトリ
# 初回実行時にモデルがダウンロードされ、このディレクトリに保存されます
cache_dir = ./models

# faster-whisperを使用するか（高速化）
# true: faster-whisper使用（推奨）、false: 標準whisper使用
use_faster_whisper = true

[audio]
# 音声サンプリングレート（Hz）
# 16000Hz: 標準的な音声認識用サンプルレート
sample_rate = 16000

# 音声処理チャンクサイズ（サンプル数）
# 一度に処理する音声サンプル数
chunk_size = 1024

# VADフレーム期間（ミリ秒）
# VADで音声検出を行うフレームの長さ
frame_duration_ms = 30

[silero_vad]
# Silero VAD settings (エンタープライズグレード)
# 音声検出閾値（0.0-1.0）
# 低い値: より敏感（多くの音声を検出）
# 高い値: より厳格（確実な音声のみ検出）
threshold = 0.05

# 音声区間検出の最小長さ（ミリ秒）
# 短い音声（「はい」等）を検出するには短く設定
min_speech_duration_ms = 10

# 無音区間の最小長さ（ミリ秒）
# 発話の区切りを判定する無音の長さ
min_silence_duration_ms = 500

[inference]
# 使用デバイス
# auto: 自動選択（推奨）
# cpu: CPU使用
# cuda: GPU使用（CUDA対応GPUが必要）
# mps: Apple Silicon GPU使用（macOS）
device = cpu

# GPU ID（cudaデバイス使用時のみ有効）
# 0, 1, 2...: 特定のGPU番号を指定
# auto: 自動選択（メモリ使用量が最も少ないGPU）
gpu_id = auto

# 計算精度（faster-whisper使用時のみ有効）
# float16, int8_float16, int8
# float16: 高精度・高速（GPU推奨）
# int8_float16: バランス型
# int8: 低メモリ・高速（CPU推奨）
; compute_type = float16
compute_type = int8

# CPUスレッド数（CPU使用時のみ有効）
# 0: 自動設定
cpu_threads = 0

# ビームサイズ（認識精度に影響）
# 値が大きいほど精度向上、処理時間増加
# 推奨: CPU=1〜3, GPU=5〜10
# 理論上の上限なし（10以上は効果薄い）
beam_size = 5

[recognizer]
# 音声検出の設定

# 音声レベル最小閾値（0.0-1.0）
# キータッチ音や雑音除去のための音声レベル閾値
min_audio_level = 0.001

# 無音継続時間（秒）
# フレーズの終わりとして認識される無音の最小の長さ
pause_threshold = 0.8

# 最小音声継続時間（秒）
# 発話音声をフレーズとみなすまでの発話音声の最小秒数
phrase_threshold = 0.3

# 最大音声継続時間（秒）
# これより長い音声セグメントは分割されます
# Whisperの最大処理時間制限（30秒）を考慮
max_duration = 30.0

# 先頭/末尾パディング（ms）
# 先頭欠け対策: 発話開始前に直近の音を付加
# 語尾欠け対策: 終了時に少量の無音を付加
pre_speech_padding_ms = 300
post_speech_padding_ms = 150

[whisper]
# Whisper固有の設定

# 言語指定（推奨: ja）
# ja: 日本語、en: 英語、auto: 自動検出
language = ja

# タスク
# transcribe: 音声認識のみ
# translate: 音声認識＋英語翻訳
task = transcribe

# 初期プロンプト（認識精度向上のヒント）
# 空欄: なし
# 例: "こんにちは。今日は良い天気ですね。"
initial_prompt = 戦争のゲーム配信なので銃器や兵器の名称や軍事用語が多数出てきます。配信者は男性で汚い口調で話します。

# VADフィルター有効化
# true: VADで無音部分を事前除去（推奨）
# false: VAD無効
vad_filter = true

# 条件付き確率閾値
# これ以下の確率の結果は除外（0.0-1.0）
condition_on_previous_text = true

# 温度パラメータ（生成のランダム性）
# 0.0: 決定的、1.0: ランダム性高
temperature = 0.0

[websocket]
# WebSocket MCP接続設定
# zagaroidサーバーに接続してJSON-RPC 2.0通信を行います

# 接続先ホスト
# localhost: 同一PC内のアプリケーション
# IPアドレス: ネットワーク経由での接続
host = 127.0.0.1

# 接続先ポート番号
# zagaroidのMCPサーバーポート: 50001
port = 50001

[filtering]
# 基本的なテキストフィルタリング設定

# 最小文字数フィルタ
# この文字数未満の認識結果は除外されます（ノイズ除去）
min_length = 1

# 空白のみの結果を除外
# true: 空白のみの結果を除外、false: 除外しない
exclude_whitespace_only = true

[debug]
# デバッグ情報表示
# true: 音声レベル、プログレスバー、デバッグ情報を表示
# false: デバッグ情報を非表示
show_debug = true

# 認識テキスト表示
# true: 認識テキストを表示
# false: 認識テキストを非表示
show_transcription = true
